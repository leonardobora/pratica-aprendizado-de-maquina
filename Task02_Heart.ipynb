{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardobora/pratica-aprendizado-de-maquina/blob/main/Task02_Heart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "h8Df6V_1ItxQ",
        "outputId": "10fb3ac6-4f23-47e1-b992-12678aad05ef"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'SimpleITK'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3101744322>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SimpleITK'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import SimpleITK as sitk\n",
        "from skimage.transform import resize\n",
        "\n",
        "# 1. Configuração do Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Caminhos do dataset (ajuste conforme sua estrutura)\n",
        "dataset_path = '/content/drive/MyDrive/Medical_Decathlon/Task02_Heart'\n",
        "images_dir = os.path.join(dataset_path, 'imagesTr')\n",
        "masks_dir = os.path.join(dataset_path, 'labelsTr')\n",
        "\n",
        "# 3. Funções de carregamento melhoradas\n",
        "def load_volume(filepath):\n",
        "    \"\"\"Carrega volume 3D e retorna array numpy com orientação correta\"\"\"\n",
        "    img = nib.load(filepath)\n",
        "    data = img.get_fdata()\n",
        "    data = np.transpose(data, (2, 1, 0))  # Corrige orientação\n",
        "    return data\n",
        "\n",
        "def preprocess_volume(volume, target_size=(128, 128)):\n",
        "    \"\"\"Pré-processa volume 3D com preservação de proporções\"\"\"\n",
        "    processed = []\n",
        "    for slice_idx in range(volume.shape[0]):\n",
        "        # Redimensionamento inteligente mantendo aspect ratio\n",
        "        slice_img = volume[slice_idx, :, :]\n",
        "\n",
        "        # Normalização baseada em percentis (melhor para imagens médicas)\n",
        "        p2 = np.percentile(slice_img, 2)\n",
        "        p98 = np.percentile(slice_img, 98)\n",
        "        slice_norm = np.clip((slice_img - p2) / (p98 - p2 + 1e-8), 0, 1)\n",
        "\n",
        "        # Redimensionamento com preservação de proporções\n",
        "        slice_resized = resize(slice_norm, target_size,\n",
        "                              order=1, mode='constant',\n",
        "                              preserve_range=True, anti_aliasing=True)\n",
        "        processed.append(slice_resized)\n",
        "    return np.array(processed)\n",
        "\n",
        "# 4. Carregamento correto do dataset multiclasse\n",
        "X, y = [], []\n",
        "\n",
        "# Listar apenas arquivos de imagens válidos\n",
        "image_files = [f for f in sorted(os.listdir(images_dir))\n",
        "              if f.endswith('.nii.gz') and '_0000' in f]\n",
        "\n",
        "for file in image_files:\n",
        "    img_path = os.path.join(images_dir, file)\n",
        "    mask_path = os.path.join(masks_dir, file.replace('_0000', ''))\n",
        "\n",
        "    # Verificar se máscara correspondente existe\n",
        "    if not os.path.exists(mask_path):\n",
        "        print(f\"Aviso: Máscara não encontrada para {file}\")\n",
        "        continue\n",
        "\n",
        "    # Carregar volumes\n",
        "    img_volume = load_volume(img_path)\n",
        "    mask_volume = load_volume(mask_path)\n",
        "\n",
        "    # Pré-processar\n",
        "    img_processed = preprocess_volume(img_volume)\n",
        "    mask_processed = preprocess_volume(mask_volume, target_size=(128, 128))\n",
        "\n",
        "    # Preservar informações multiclasse\n",
        "    X.append(img_processed)\n",
        "    y.append(mask_processed)\n",
        "\n",
        "# 5. Preparação dos dados\n",
        "X = np.concatenate(X, axis=0)[..., np.newaxis]  # Add channel dimension\n",
        "y = np.concatenate(y, axis=0)\n",
        "\n",
        "# Converter máscaras para one-hot encoding (3 classes: fundo + 2 estruturas cardíacas)\n",
        "y = utils.to_categorical(y, num_classes=3)\n",
        "\n",
        "# 6. Divisão dos dados mantendo volumes intactos\n",
        "# Estratégia: dividir por volume em vez de por fatias\n",
        "vol_sizes = [vol.shape[0] for vol in X]\n",
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(vol_sizes)),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Criar máscaras de seleção\n",
        "train_mask = np.zeros(len(X), dtype=bool)\n",
        "val_mask = np.zeros(len(X), dtype=bool)\n",
        "\n",
        "start = 0\n",
        "for i, size in enumerate(vol_sizes):\n",
        "    end = start + size\n",
        "    if i in train_idx:\n",
        "        train_mask[start:end] = True\n",
        "    else:\n",
        "        val_mask[start:end] = True\n",
        "    start = end\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_val, y_val = X[val_mask], y[val_mask]\n",
        "\n",
        "print(f\"Dados de treino: {X_train.shape[0]} fatias\")\n",
        "print(f\"Dados de validação: {X_val.shape[0]} fatias\")\n",
        "print(f\"Distribuição de classes: {np.unique(np.argmax(y_train, axis=-1), return_counts=True)}\")\n",
        "\n",
        "# 7. Visualização de amostra\n",
        "def plot_sample(idx):\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    ax[0].imshow(X_train[idx].squeeze(), cmap='gray')\n",
        "    ax[0].set_title('Imagem de entrada')\n",
        "\n",
        "    mask = np.argmax(y_train[idx], axis=-1)\n",
        "    ax[1].imshow(mask, cmap='jet')\n",
        "    ax[1].set_title('Máscara verdadeira')\n",
        "\n",
        "    # Mostrar estruturas separadas\n",
        "    structures = []\n",
        "    for i in range(1, 3):  # Classes 1 e 2\n",
        "        structures.append(mask == i)\n",
        "\n",
        "    ax[2].imshow(structures[0], cmap='Reds', alpha=0.5)\n",
        "    ax[2].imshow(structures[1], cmap='Blues', alpha=0.5)\n",
        "    ax[2].set_title('Estruturas cardíacas')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_sample(np.random.randint(0, len(X_train)))"
      ]
    }
  ]
}