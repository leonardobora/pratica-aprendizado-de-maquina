{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba34b06d",
   "metadata": {},
   "source": [
    "# ü´Ä Heart Segmentation Advanced - Model Architecture\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/leonardobora/pratica-aprendizado-de-maquina/blob/main/Heart_Segmentation_Advanced/03_Model_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## üìã Objetivos deste Notebook\n",
    "\n",
    "Este notebook implementa arquiteturas avan√ßadas de redes neurais para segmenta√ß√£o card√≠aca:\n",
    "\n",
    "- üèóÔ∏è **U-Net Base Aprimorada** com melhorias modernas\n",
    "- üß† **Backbones Pr√©-treinados** (ResNet, EfficientNet, DenseNet)\n",
    "- ‚ö° **Mecanismos de Aten√ß√£o** (Attention Gates, Self-Attention)\n",
    "- üîß **Normaliza√ß√£o por Lotes** e Dropout\n",
    "- üéØ **Variantes Arquiteturais** (U-Net++, Attention U-Net)\n",
    "- üìä **Compara√ß√£o de Modelos** e an√°lise de complexidade\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è PR√â-REQUISITOS**: \n",
    "- Execute `00_Setup_and_Configuration.ipynb`\n",
    "- Execute `01_Data_Analysis_and_Preprocessing.ipynb`\n",
    "- Execute `02_Data_Augmentation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d109c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configura√ß√µes carregadas\n",
      "üîß PyTorch version: 2.7.1+cpu\n",
      "üöÄ Device: cpu\n",
      "üìö Setup completo!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üìö SETUP E CONFIGURA√á√ïES\n",
    "# =============================================================================\n",
    "\n",
    "# Carregar configura√ß√µes do projeto\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    with open('project_config.json', 'r') as f:\n",
    "        project_config = json.load(f)\n",
    "    print(\"‚úÖ Configura√ß√µes carregadas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Execute primeiro 00_Setup_and_Configuration.ipynb\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Imports principais\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Verificar GPU\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"üìö Setup completo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccba8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Blocos b√°sicos definidos\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üß± BLOCOS B√ÅSICOS DE CONSTRU√á√ÉO\n",
    "# =============================================================================\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Bloco de convolu√ß√£o b√°sico com BatchNorm e Dropout\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, \n",
    "                 batch_norm=True, dropout_rate=0.0):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Primeira convolu√ß√£o\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "                              padding=kernel_size//2, bias=not batch_norm)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, \n",
    "                              padding=kernel_size//2, bias=not batch_norm)\n",
    "        \n",
    "        # Normaliza√ß√£o\n",
    "        if batch_norm:\n",
    "            self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Dropout\n",
    "        if dropout_rate > 0:\n",
    "            self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        \n",
    "        # Ativa√ß√£o\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Primeira convolu√ß√£o\n",
    "        out = self.conv1(x)\n",
    "        if self.batch_norm:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        if self.dropout_rate > 0:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        # Segunda convolu√ß√£o\n",
    "        out = self.conv2(out)\n",
    "        if self.batch_norm:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Bloco residual com skip connection\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, \n",
    "                 batch_norm=True, dropout_rate=0.0):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv_block = ConvBlock(in_channels, out_channels, kernel_size, \n",
    "                                   batch_norm, dropout_rate)\n",
    "        \n",
    "        # Skip connection (1x1 conv se necess√°rio)\n",
    "        self.skip_conv = None\n",
    "        if in_channels != out_channels:\n",
    "            self.skip_conv = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "            if batch_norm:\n",
    "                self.skip_bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Main path\n",
    "        out = self.conv_block(x)\n",
    "        \n",
    "        # Skip connection\n",
    "        if self.skip_conv is not None:\n",
    "            skip = self.skip_conv(x)\n",
    "            if hasattr(self, 'skip_bn'):\n",
    "                skip = self.skip_bn(skip)\n",
    "        else:\n",
    "            skip = x\n",
    "        \n",
    "        # Add skip connection\n",
    "        out = out + skip\n",
    "        return self.relu(out)\n",
    "\n",
    "print(\"‚úÖ Blocos b√°sicos definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mecanismos de aten√ß√£o definidos\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =============================================================================\n",
    "# ‚ö° MECANISMOS DE ATEN√á√ÉO\n",
    "# =============================================================================\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    \"\"\"Attention Gate para U-Net\"\"\"\n",
    "    \n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            F_g: n√∫mero de canais do gating signal\n",
    "            F_l: n√∫mero de canais do feature map \n",
    "            F_int: n√∫mero de canais intermedi√°rios\n",
    "        \"\"\"\n",
    "        super(AttentionGate, self).__init__()\n",
    "        \n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            g: Gating signal do decoder\n",
    "            x: Feature map do encoder\n",
    "        \"\"\"\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        \n",
    "        return x * psi\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Self-Attention mechanism\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # Query, Key, Value projections\n",
    "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        \n",
    "        # Learnable parameter\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input feature maps (B, C, H, W)\n",
    "        Returns:\n",
    "            out: self attention value + input feature\n",
    "            attention: attention map (B, N, N)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.size()\n",
    "        N = H * W\n",
    "        \n",
    "        # Generate Q, K, V\n",
    "        q = self.query_conv(x).view(B, -1, N).permute(0, 2, 1)  # B, N, C//8\n",
    "        k = self.key_conv(x).view(B, -1, N)                     # B, C//8, N\n",
    "        v = self.value_conv(x).view(B, -1, N)                   # B, C, N\n",
    "        \n",
    "        # Attention computation\n",
    "        attention = torch.bmm(q, k)                              # B, N, N\n",
    "        attention = self.softmax(attention)\n",
    "        \n",
    "        out = torch.bmm(v, attention.permute(0, 2, 1))          # B, C, N\n",
    "        out = out.view(B, C, H, W)                              # B, C, H, W\n",
    "        \n",
    "        # Apply learnable parameter and residual connection\n",
    "        out = self.gamma * out + x\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ChannelAttention(nn.Module):  \n",
    "    \"\"\"Channel Attention (SE Block)\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.global_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "print(\"‚úÖ Mecanismos de aten√ß√£o definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae0a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ TESTANDO ARQUITETURA\n",
      "==================================================\n",
      "‚úÖ Enhanced U-Net criada:\n",
      "   üìä Canais entrada: 1\n",
      "   üè∑Ô∏è Classes: 3\n",
      "   üîß Filtros base: 64\n",
      "   ‚ö° Aten√ß√£o: True\n",
      "   üîó Residual: False\n",
      "   üíß Dropout: 0.1\n",
      "üìä Par√¢metros totais: 31,388,143\n",
      "üìä Par√¢metros trein√°veis: 31,388,143\n",
      "üîç Input shape: torch.Size([1, 1, 128, 128])\n",
      "üéØ Output shape: torch.Size([1, 3, 128, 128])\n",
      "‚úÖ Teste de arquitetura conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üèóÔ∏è U-NET BASE APRIMORADA\n",
    "# =============================================================================\n",
    "\n",
    "class EnhancedUNet(nn.Module):\n",
    "    \"\"\"U-Net aprimorada com op√ß√µes modernas\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, num_classes=3, filters_base=64, \n",
    "                 use_attention=True, use_residual=False, dropout_rate=0.1):\n",
    "        super(EnhancedUNet, self).__init__()\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        self.use_residual = use_residual\n",
    "        \n",
    "        # Encoder\n",
    "        if use_residual:\n",
    "            self.encoder1 = ResidualBlock(in_channels, filters_base, dropout_rate=dropout_rate)\n",
    "            self.encoder2 = ResidualBlock(filters_base, filters_base*2, dropout_rate=dropout_rate)  \n",
    "            self.encoder3 = ResidualBlock(filters_base*2, filters_base*4, dropout_rate=dropout_rate)\n",
    "            self.encoder4 = ResidualBlock(filters_base*4, filters_base*8, dropout_rate=dropout_rate)\n",
    "        else:\n",
    "            self.encoder1 = ConvBlock(in_channels, filters_base, dropout_rate=dropout_rate)\n",
    "            self.encoder2 = ConvBlock(filters_base, filters_base*2, dropout_rate=dropout_rate)\n",
    "            self.encoder3 = ConvBlock(filters_base*2, filters_base*4, dropout_rate=dropout_rate)\n",
    "            self.encoder4 = ConvBlock(filters_base*4, filters_base*8, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(filters_base*8, filters_base*16, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Decoder upsampling\n",
    "        self.upconv4 = nn.ConvTranspose2d(filters_base*16, filters_base*8, 2, stride=2)\n",
    "        self.upconv3 = nn.ConvTranspose2d(filters_base*8, filters_base*4, 2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(filters_base*4, filters_base*2, 2, stride=2)\n",
    "        self.upconv1 = nn.ConvTranspose2d(filters_base*2, filters_base, 2, stride=2)\n",
    "        \n",
    "        # Decoder conv blocks\n",
    "        if use_residual:\n",
    "            self.decoder4 = ResidualBlock(filters_base*16, filters_base*8, dropout_rate=dropout_rate)\n",
    "            self.decoder3 = ResidualBlock(filters_base*8, filters_base*4, dropout_rate=dropout_rate)\n",
    "            self.decoder2 = ResidualBlock(filters_base*4, filters_base*2, dropout_rate=dropout_rate)\n",
    "            self.decoder1 = ResidualBlock(filters_base*2, filters_base, dropout_rate=dropout_rate)\n",
    "        else:\n",
    "            self.decoder4 = ConvBlock(filters_base*16, filters_base*8, dropout_rate=dropout_rate)\n",
    "            self.decoder3 = ConvBlock(filters_base*8, filters_base*4, dropout_rate=dropout_rate)\n",
    "            self.decoder2 = ConvBlock(filters_base*4, filters_base*2, dropout_rate=dropout_rate)\n",
    "            self.decoder1 = ConvBlock(filters_base*2, filters_base, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Attention gates\n",
    "        if use_attention:\n",
    "            self.att4 = AttentionGate(filters_base*8, filters_base*8, filters_base*4)\n",
    "            self.att3 = AttentionGate(filters_base*4, filters_base*4, filters_base*2)\n",
    "            self.att2 = AttentionGate(filters_base*2, filters_base*2, filters_base)\n",
    "            self.att1 = AttentionGate(filters_base, filters_base, filters_base//2)\n",
    "        \n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Final classifier\n",
    "        self.final = nn.Conv2d(filters_base, num_classes, 1)\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced U-Net criada:\")\n",
    "        print(f\"   üìä Canais entrada: {in_channels}\")\n",
    "        print(f\"   üè∑Ô∏è Classes: {num_classes}\")\n",
    "        print(f\"   üîß Filtros base: {filters_base}\")\n",
    "        print(f\"   ‚ö° Aten√ß√£o: {use_attention}\")\n",
    "        print(f\"   üîó Residual: {use_residual}\")\n",
    "        print(f\"   üíß Dropout: {dropout_rate}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)          # N, 64, H, W\n",
    "        enc2 = self.encoder2(self.pool(enc1))   # N, 128, H/2, W/2\n",
    "        enc3 = self.encoder3(self.pool(enc2))   # N, 256, H/4, W/4\n",
    "        enc4 = self.encoder4(self.pool(enc3))   # N, 512, H/8, W/8\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(enc4))  # N, 1024, H/16, W/16\n",
    "        \n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(bottleneck)  # N, 512, H/8, W/8\n",
    "        if self.use_attention:\n",
    "            enc4 = self.att4(dec4, enc4)\n",
    "        dec4 = torch.cat([dec4, enc4], dim=1)  # N, 1024, H/8, W/8\n",
    "        dec4 = self.decoder4(dec4)       # N, 512, H/8, W/8\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)        # N, 256, H/4, W/4\n",
    "        if self.use_attention:\n",
    "            enc3 = self.att3(dec3, enc3)\n",
    "        dec3 = torch.cat([dec3, enc3], dim=1)  # N, 512, H/4, W/4\n",
    "        dec3 = self.decoder3(dec3)       # N, 256, H/4, W/4\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)        # N, 128, H/2, W/2\n",
    "        if self.use_attention:\n",
    "            enc2 = self.att2(dec2, enc2)\n",
    "        dec2 = torch.cat([dec2, enc2], dim=1)  # N, 256, H/2, W/2\n",
    "        dec2 = self.decoder2(dec2)       # N, 128, H/2, W/2\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)        # N, 64, H, W\n",
    "        if self.use_attention:\n",
    "            enc1 = self.att1(dec1, enc1)\n",
    "        dec1 = torch.cat([dec1, enc1], dim=1)  # N, 128, H, W\n",
    "        dec1 = self.decoder1(dec1)       # N, 64, H, W\n",
    "        \n",
    "        # Final output\n",
    "        output = self.final(dec1)        # N, num_classes, H, W\n",
    "        \n",
    "        return output\n",
    "\n",
    "def create_enhanced_unet(in_channels=1, num_classes=3, filters_base=64, \n",
    "                        use_attention=True, use_residual=False, dropout_rate=0.1):\n",
    "    \"\"\"Factory function para criar Enhanced U-Net\"\"\"\n",
    "    return EnhancedUNet(in_channels, num_classes, filters_base, \n",
    "                       use_attention, use_residual, dropout_rate)\n",
    "\n",
    "# Teste da arquitetura\n",
    "print(\"\\nüß™ TESTANDO ARQUITETURA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model = create_enhanced_unet()\n",
    "print(f\"üìä Par√¢metros totais: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üìä Par√¢metros trein√°veis: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Teste com entrada dummy\n",
    "test_input = torch.randn(1, 1, 128, 128)\n",
    "print(f\"üîç Input shape: {test_input.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_input)\n",
    "    print(f\"üéØ Output shape: {test_output.shape}\")\n",
    "\n",
    "print(\"‚úÖ Teste de arquitetura conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üß† BACKBONES PR√â-TREINADOS\n",
    "# =============================================================================\n",
    "\n",
    "def create_backbone_encoder(backbone_name='resnet50', input_shape=(128, 128, 3)):\n",
    "    \"\"\"\n",
    "    Cria encoder baseado em backbone pr√©-treinado\n",
    "    \n",
    "    Args:\n",
    "        backbone_name: Nome do backbone ('resnet50', 'efficientnet-b0', 'densenet121')\n",
    "        input_shape: Forma da entrada\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (encoder_model, skip_connections_names)\n",
    "    \"\"\"\n",
    "    \n",
    "    if backbone_name == 'resnet50':\n",
    "        backbone = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "        \n",
    "        # Camadas para skip connections\n",
    "        skip_layers = [\n",
    "            'conv1_relu',           # 64x64\n",
    "            'conv2_block3_out',     # 32x32  \n",
    "            'conv3_block4_out',     # 16x16\n",
    "            'conv4_block6_out',     # 8x8\n",
    "            'conv5_block3_out'      # 4x4\n",
    "        ]\n",
    "        \n",
    "    elif backbone_name == 'efficientnet-b0':\n",
    "        backbone = EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "        \n",
    "        # Camadas para skip connections (EfficientNet)\n",
    "        skip_layers = [\n",
    "            'block2a_expand_activation',  # 64x64\n",
    "            'block3a_expand_activation',  # 32x32\n",
    "            'block4a_expand_activation',  # 16x16\n",
    "            'block6a_expand_activation',  # 8x8\n",
    "            'top_activation'              # 4x4\n",
    "        ]\n",
    "        \n",
    "    elif backbone_name == 'densenet121':\n",
    "        backbone = DenseNet121(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "        \n",
    "        # Camadas para skip connections (DenseNet)\n",
    "        skip_layers = [\n",
    "            'conv1/relu',                    # 64x64\n",
    "            'pool2_pool',                    # 32x32\n",
    "            'pool3_pool',                    # 16x16\n",
    "            'pool4_pool',                    # 8x8\n",
    "            'relu'                           # 4x4\n",
    "        ]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Backbone n√£o suportado: {backbone_name}\")\n",
    "    \n",
    "    # Freezar algumas camadas iniciais\n",
    "    for layer in backbone.layers[:50]:  # Freezar primeiras 50 camadas\n",
    "        layer.trainable = False\n",
    "    \n",
    "    print(f\"üß† Backbone {backbone_name} carregado\")\n",
    "    print(f\"   Par√¢metros totais: {backbone.count_params():,}\")\n",
    "    print(f\"   Par√¢metros trein√°veis: {sum([tf.keras.utils.count_params(w) for w in backbone.trainable_weights]):,}\")\n",
    "    \n",
    "    return backbone, skip_layers\n",
    "\n",
    "def create_unet_with_backbone(backbone_name='resnet50', input_shape=(128, 128, 1), \n",
    "                             num_classes=3, use_attention=True):\n",
    "    \"\"\"\n",
    "    Cria U-Net com backbone pr√©-treinado\n",
    "    \n",
    "    Args:\n",
    "        backbone_name: Nome do backbone\n",
    "        input_shape: Forma da entrada\n",
    "        num_classes: N√∫mero de classes\n",
    "        use_attention: Usar attention gates\n",
    "    \n",
    "    Returns:\n",
    "        Model: Modelo Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ajustar input para 3 canais se necess√°rio\n",
    "    if input_shape[-1] == 1:\n",
    "        backbone_input_shape = (*input_shape[:2], 3)\n",
    "        \n",
    "        # Input original\n",
    "        inputs = Input(shape=input_shape, name='input')\n",
    "        \n",
    "        # Converter para 3 canais (repetir canal)\n",
    "        x = layers.Concatenate()([inputs, inputs, inputs])\n",
    "    else:\n",
    "        backbone_input_shape = input_shape\n",
    "        inputs = Input(shape=input_shape, name='input')\n",
    "        x = inputs\n",
    "    \n",
    "    # Criar backbone encoder\n",
    "    backbone, skip_layers = create_backbone_encoder(backbone_name, backbone_input_shape)\n",
    "    \n",
    "    # Extrair features em diferentes escalas\n",
    "    skip_features = []\n",
    "    x = backbone(x)\n",
    "    \n",
    "    # Para este exemplo, vamos usar uma abordagem simplificada\n",
    "    # Criando features artificiais para demonstra√ß√£o\n",
    "    print(\"üîß Construindo decoder com backbone...\")\n",
    "    \n",
    "    # Decoder simplificado (vers√£o demonstrativa)\n",
    "    # Nivel 4 (4x4 -> 8x8)\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    x = ConvBlock(512, name='decoder_4')(x)\n",
    "    \n",
    "    # Nivel 3 (8x8 -> 16x16) \n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    x = ConvBlock(256, name='decoder_3')(x)\n",
    "    \n",
    "    # Nivel 2 (16x16 -> 32x32)\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    x = ConvBlock(128, name='decoder_2')(x)\n",
    "    \n",
    "    # Nivel 1 (32x32 -> 64x64)\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    x = ConvBlock(64, name='decoder_1')(x)\n",
    "    \n",
    "    # Final (64x64 -> 128x128)\n",
    "    x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    x = ConvBlock(32, name='decoder_0')(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name=f'UNet_{backbone_name}')\n",
    "    \n",
    "    print(f\"‚úÖ U-Net com {backbone_name} criada: {model.count_params():,} par√¢metros\")\n",
    "    return model\n",
    "\n",
    "# Testar backbones\n",
    "print(\"üß™ Testando backbones pr√©-treinados...\")\n",
    "\n",
    "try:\n",
    "    # U-Net com ResNet50\n",
    "    unet_resnet = create_unet_with_backbone(\n",
    "        backbone_name='resnet50',\n",
    "        input_shape=(128, 128, 1),\n",
    "        num_classes=3\n",
    "    )\n",
    "    \n",
    "    # U-Net com EfficientNet-B0\n",
    "    unet_efficientnet = create_unet_with_backbone(\n",
    "        backbone_name='efficientnet-b0',\n",
    "        input_shape=(128, 128, 1),\n",
    "        num_classes=3\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Modelos com backbones criados com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao criar modelos com backbone: {e}\")\n",
    "    print(\"Continuando com modelos b√°sicos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f526b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üéØ U-NET++ (NESTED U-NET)\n",
    "# =============================================================================\n",
    "\n",
    "def create_unet_plusplus(input_shape=(128, 128, 1), num_classes=3, \n",
    "                        filters_base=64, deep_supervision=True):\n",
    "    \"\"\"\n",
    "    Implementa U-Net++ (Nested U-Net)\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Forma da entrada\n",
    "        num_classes: N√∫mero de classes\n",
    "        filters_base: N√∫mero base de filtros\n",
    "        deep_supervision: Usar supervis√£o profunda\n",
    "    \n",
    "    Returns:\n",
    "        Model: Modelo U-Net++\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # Encoder pathway\n",
    "    print(\"üîß Construindo U-Net++ Encoder...\")\n",
    "    \n",
    "    # Level 0 (128x128)\n",
    "    x00 = ConvBlock(filters_base, name='conv_0_0')(inputs)\n",
    "    pool0 = layers.MaxPooling2D(2)(x00)\n",
    "    \n",
    "    # Level 1 (64x64)\n",
    "    x10 = ConvBlock(filters_base*2, name='conv_1_0')(pool0)\n",
    "    pool1 = layers.MaxPooling2D(2)(x10)\n",
    "    \n",
    "    # Level 2 (32x32)\n",
    "    x20 = ConvBlock(filters_base*4, name='conv_2_0')(pool1)\n",
    "    pool2 = layers.MaxPooling2D(2)(x20)\n",
    "    \n",
    "    # Level 3 (16x16)\n",
    "    x30 = ConvBlock(filters_base*8, name='conv_3_0')(pool2)\n",
    "    pool3 = layers.MaxPooling2D(2)(x30)\n",
    "    \n",
    "    # Level 4 (8x8) - Bottleneck\n",
    "    x40 = ConvBlock(filters_base*16, name='conv_4_0')(pool3)\n",
    "    \n",
    "    # Nested pathways\n",
    "    print(\"üîß Construindo U-Net++ Nested Pathways...\")\n",
    "    \n",
    "    # Nested Level 0\n",
    "    up_3_1 = layers.UpSampling2D(2, interpolation='bilinear')(x40)\n",
    "    concat_3_1 = layers.Concatenate()([x30, up_3_1])\n",
    "    x31 = ConvBlock(filters_base*8, name='conv_3_1')(concat_3_1)\n",
    "    \n",
    "    # Nested Level 1\n",
    "    up_2_1 = layers.UpSampling2D(2, interpolation='bilinear')(x31)\n",
    "    concat_2_1 = layers.Concatenate()([x20, up_2_1])\n",
    "    x21 = ConvBlock(filters_base*4, name='conv_2_1')(concat_2_1)\n",
    "    \n",
    "    up_2_2 = layers.UpSampling2D(2, interpolation='bilinear')(x30)\n",
    "    concat_2_2 = layers.Concatenate()([x20, x21, up_2_2])\n",
    "    x22 = ConvBlock(filters_base*4, name='conv_2_2')(concat_2_2)\n",
    "    \n",
    "    # Nested Level 2\n",
    "    up_1_1 = layers.UpSampling2D(2, interpolation='bilinear')(x21)\n",
    "    concat_1_1 = layers.Concatenate()([x10, up_1_1])\n",
    "    x11 = ConvBlock(filters_base*2, name='conv_1_1')(concat_1_1)\n",
    "    \n",
    "    up_1_2 = layers.UpSampling2D(2, interpolation='bilinear')(x22)\n",
    "    concat_1_2 = layers.Concatenate()([x10, x11, up_1_2])\n",
    "    x12 = ConvBlock(filters_base*2, name='conv_1_2')(concat_1_2)\n",
    "    \n",
    "    up_1_3 = layers.UpSampling2D(2, interpolation='bilinear')(x31)\n",
    "    concat_1_3 = layers.Concatenate()([x10, x11, x12, up_1_3])\n",
    "    x13 = ConvBlock(filters_base*2, name='conv_1_3')(concat_1_3)\n",
    "    \n",
    "    # Final level\n",
    "    up_0_1 = layers.UpSampling2D(2, interpolation='bilinear')(x11)\n",
    "    concat_0_1 = layers.Concatenate()([x00, up_0_1])\n",
    "    x01 = ConvBlock(filters_base, name='conv_0_1')(concat_0_1)\n",
    "    \n",
    "    up_0_2 = layers.UpSampling2D(2, interpolation='bilinear')(x12)\n",
    "    concat_0_2 = layers.Concatenate()([x00, x01, up_0_2])\n",
    "    x02 = ConvBlock(filters_base, name='conv_0_2')(concat_0_2)\n",
    "    \n",
    "    up_0_3 = layers.UpSampling2D(2, interpolation='bilinear')(x13)\n",
    "    concat_0_3 = layers.Concatenate()([x00, x01, x02, up_0_3])\n",
    "    x03 = ConvBlock(filters_base, name='conv_0_3')(concat_0_3)\n",
    "    \n",
    "    up_0_4 = layers.UpSampling2D(2, interpolation='bilinear')(x31)\n",
    "    concat_0_4 = layers.Concatenate()([x00, x01, x02, x03, up_0_4])\n",
    "    x04 = ConvBlock(filters_base, name='conv_0_4')(concat_0_4)\n",
    "    \n",
    "    # Outputs\n",
    "    if deep_supervision:\n",
    "        # M√∫ltiplas sa√≠das para supervis√£o profunda\n",
    "        out1 = layers.Conv2D(num_classes, 1, activation='softmax', name='output_1')(x01)\n",
    "        out2 = layers.Conv2D(num_classes, 1, activation='softmax', name='output_2')(x02)\n",
    "        out3 = layers.Conv2D(num_classes, 1, activation='softmax', name='output_3')(x03)\n",
    "        out4 = layers.Conv2D(num_classes, 1, activation='softmax', name='output_4')(x04)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs=[out1, out2, out3, out4], name='UNet_PlusPlus')\n",
    "    else:\n",
    "        # Sa√≠da √∫nica\n",
    "        output = layers.Conv2D(num_classes, 1, activation='softmax', name='output')(x04)\n",
    "        model = Model(inputs=inputs, outputs=output, name='UNet_PlusPlus')\n",
    "    \n",
    "    print(f\"‚úÖ U-Net++ criada: {model.count_params():,} par√¢metros\")\n",
    "    return model\n",
    "\n",
    "# Testar U-Net++\n",
    "print(\"üß™ Testando U-Net++...\")\n",
    "\n",
    "try:\n",
    "    unet_plusplus = create_unet_plusplus(\n",
    "        input_shape=(128, 128, 1),\n",
    "        num_classes=3,\n",
    "        deep_supervision=False  # Simplificado para teste\n",
    "    )\n",
    "    print(\"‚úÖ U-Net++ criada com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao criar U-Net++: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8724fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä COMPARA√á√ÉO DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_model_complexity():\n",
    "    \"\"\"Analisa complexidade dos modelos criados\"\"\"\n",
    "    \n",
    "    print(\"üìä AN√ÅLISE DE COMPLEXIDADE DOS MODELOS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    models_info = []\n",
    "    \n",
    "    # Lista de modelos para analisar\n",
    "    models_to_analyze = [\n",
    "        (\"U-Net B√°sica\", unet_basic),\n",
    "        (\"U-Net + Aten√ß√£o\", unet_attention), \n",
    "        (\"U-Net + Aten√ß√£o + Residual\", unet_full),\n",
    "    ]\n",
    "    \n",
    "    # Adicionar modelos com backbone se dispon√≠veis\n",
    "    try:\n",
    "        models_to_analyze.extend([\n",
    "            (\"U-Net + ResNet50\", unet_resnet),\n",
    "            (\"U-Net + EfficientNet-B0\", unet_efficientnet),\n",
    "        ])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Adicionar U-Net++ se dispon√≠vel\n",
    "    try:\n",
    "        models_to_analyze.append((\"U-Net++\", unet_plusplus))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Analisar cada modelo\n",
    "    for name, model in models_to_analyze:\n",
    "        try:\n",
    "            total_params = model.count_params()\n",
    "            trainable_params = sum([tf.keras.utils.count_params(w) for w in model.trainable_weights])\n",
    "            non_trainable_params = total_params - trainable_params\n",
    "            \n",
    "            # Calcular FLOPs (aproximado)\n",
    "            input_shape = model.input_shape[1:]\n",
    "            flops = estimate_flops(model, input_shape)\n",
    "            \n",
    "            # Calcular tamanho do modelo em MB\n",
    "            model_size_mb = (total_params * 4) / (1024 * 1024)  # 4 bytes por par√¢metro\n",
    "            \n",
    "            info = {\n",
    "                'name': name,\n",
    "                'total_params': total_params,\n",
    "                'trainable_params': trainable_params,\n",
    "                'non_trainable_params': non_trainable_params,\n",
    "                'model_size_mb': model_size_mb,\n",
    "                'flops': flops\n",
    "            }\n",
    "            \n",
    "            models_info.append(info)\n",
    "            \n",
    "            print(f\"\\nüèóÔ∏è {name}:\")\n",
    "            print(f\"   üìä Par√¢metros totais: {total_params:,}\")\n",
    "            print(f\"   üîß Par√¢metros trein√°veis: {trainable_params:,}\")\n",
    "            print(f\"   üîí Par√¢metros n√£o-trein√°veis: {non_trainable_params:,}\")\n",
    "            print(f\"   üíæ Tamanho do modelo: {model_size_mb:.2f} MB\")\n",
    "            print(f\"   ‚ö° FLOPs estimados: {flops:,}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao analisar {name}: {e}\")\n",
    "    \n",
    "    # Criar visualiza√ß√£o comparativa\n",
    "    visualize_model_comparison(models_info)\n",
    "    \n",
    "    return models_info\n",
    "\n",
    "def estimate_flops(model, input_shape):\n",
    "    \"\"\"Estima FLOPs do modelo (aproxima√ß√£o simples)\"\"\"\n",
    "    total_flops = 0\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            # FLOPs para Conv2D = (kernel_size^2 * input_channels * output_channels * output_height * output_width)\n",
    "            if hasattr(layer, 'kernel_size') and hasattr(layer, 'filters'):\n",
    "                kernel_h, kernel_w = layer.kernel_size\n",
    "                output_channels = layer.filters\n",
    "                \n",
    "                # Aproxima√ß√£o grosseira\n",
    "                flops_per_conv = kernel_h * kernel_w * output_channels * (input_shape[0] * input_shape[1])\n",
    "                total_flops += flops_per_conv\n",
    "        \n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            if hasattr(layer, 'units'):\n",
    "                # FLOPs para Dense = input_size * output_size\n",
    "                total_flops += layer.units * 1000  # Aproxima√ß√£o\n",
    "    \n",
    "    return total_flops\n",
    "\n",
    "def visualize_model_comparison(models_info):\n",
    "    \"\"\"Visualiza compara√ß√£o entre modelos\"\"\"\n",
    "    \n",
    "    if not models_info:\n",
    "        print(\"‚ö†Ô∏è Nenhum modelo para comparar\")\n",
    "        return\n",
    "    \n",
    "    names = [info['name'] for info in models_info]\n",
    "    total_params = [info['total_params'] for info in models_info]\n",
    "    model_sizes = [info['model_size_mb'] for info in models_info]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('üìä Compara√ß√£o de Complexidade dos Modelos', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Gr√°fico 1: N√∫mero de par√¢metros\n",
    "    axes[0, 0].bar(names, total_params, color='skyblue', alpha=0.7)\n",
    "    axes[0, 0].set_title('N√∫mero Total de Par√¢metros')\n",
    "    axes[0, 0].set_ylabel('Par√¢metros')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for i, v in enumerate(total_params):\n",
    "        axes[0, 0].text(i, v, f'{v:,.0f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Gr√°fico 2: Tamanho do modelo\n",
    "    axes[0, 1].bar(names, model_sizes, color='lightcoral', alpha=0.7)\n",
    "    axes[0, 1].set_title('Tamanho do Modelo')\n",
    "    axes[0, 1].set_ylabel('Tamanho (MB)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for i, v in enumerate(model_sizes):\n",
    "        axes[0, 1].text(i, v, f'{v:.1f}MB', ha='center', va='bottom')\n",
    "    \n",
    "    # Gr√°fico 3: Par√¢metros trein√°veis vs n√£o-trein√°veis\n",
    "    trainable = [info['trainable_params'] for info in models_info]\n",
    "    non_trainable = [info['non_trainable_params'] for info in models_info]\n",
    "    \n",
    "    x = np.arange(len(names))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 0].bar(x - width/2, trainable, width, label='Trein√°veis', color='green', alpha=0.7)\n",
    "    axes[1, 0].bar(x + width/2, non_trainable, width, label='N√£o-trein√°veis', color='red', alpha=0.7)\n",
    "    axes[1, 0].set_title('Par√¢metros Trein√°veis vs N√£o-trein√°veis')\n",
    "    axes[1, 0].set_ylabel('Par√¢metros')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(names, rotation=45)\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Gr√°fico 4: Efficiency score (par√¢metros / MB)\n",
    "    efficiency = [params / size if size > 0 else 0 for params, size in zip(total_params, model_sizes)]\n",
    "    axes[1, 1].bar(names, efficiency, color='gold', alpha=0.7)\n",
    "    axes[1, 1].set_title('Efici√™ncia (Par√¢metros por MB)')\n",
    "    axes[1, 1].set_ylabel('Par√¢metros/MB')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Executar an√°lise\n",
    "models_info = analyze_model_complexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c84f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üéØ TESTE DE INFER√äNCIA DOS MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def test_model_inference():\n",
    "    \"\"\"Testa infer√™ncia dos modelos criados\"\"\"\n",
    "    \n",
    "    print(\"üéØ TESTANDO INFER√äNCIA DOS MODELOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Criar dados de teste\n",
    "    batch_size = 2\n",
    "    test_input = tf.random.normal([batch_size, 128, 128, 1])\n",
    "    \n",
    "    models_to_test = [\n",
    "        (\"U-Net B√°sica\", unet_basic),\n",
    "        (\"U-Net + Aten√ß√£o\", unet_attention),\n",
    "        (\"U-Net + Aten√ß√£o + Residual\", unet_full),\n",
    "    ]\n",
    "    \n",
    "    # Adicionar outros modelos se dispon√≠veis\n",
    "    try:\n",
    "        models_to_test.extend([\n",
    "            (\"U-Net + ResNet50\", unet_resnet),\n",
    "            (\"U-Net + EfficientNet-B0\", unet_efficientnet),\n",
    "        ])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        models_to_test.append((\"U-Net++\", unet_plusplus))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    inference_results = []\n",
    "    \n",
    "    for name, model in models_to_test:\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Testando {name}...\")\n",
    "            \n",
    "            # Medir tempo de infer√™ncia\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            predictions = model(test_input, training=False)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            \n",
    "            # Verificar forma da sa√≠da\n",
    "            if isinstance(predictions, list):\n",
    "                output_shape = predictions[0].shape\n",
    "                print(f\"   üì§ Sa√≠da m√∫ltipla: {len(predictions)} outputs\")\n",
    "                print(f\"   üìê Forma principal: {output_shape}\")\n",
    "            else:\n",
    "                output_shape = predictions.shape\n",
    "                print(f\"   üìê Forma da sa√≠da: {output_shape}\")\n",
    "            \n",
    "            print(f\"   ‚è±Ô∏è Tempo de infer√™ncia: {inference_time:.4f}s\")\n",
    "            print(f\"   üöÄ FPS (aprox): {batch_size/inference_time:.2f}\")\n",
    "            \n",
    "            # Verificar range de valores\n",
    "            if isinstance(predictions, list):\n",
    "                pred_to_check = predictions[0]\n",
    "            else:\n",
    "                pred_to_check = predictions\n",
    "                \n",
    "            print(f\"   üìä Range de valores: [{tf.reduce_min(pred_to_check):.4f}, {tf.reduce_max(pred_to_check):.4f}]\")\n",
    "            print(f\"   üìà Soma softmax (deve ser ~1): {tf.reduce_mean(tf.reduce_sum(pred_to_check, axis=-1)):.4f}\")\n",
    "            \n",
    "            inference_results.append({\n",
    "                'name': name,\n",
    "                'inference_time': inference_time,\n",
    "                'fps': batch_size/inference_time,\n",
    "                'output_shape': output_shape,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            print(f\"   ‚úÖ Teste bem-sucedido!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro durante infer√™ncia: {e}\")\n",
    "            inference_results.append({\n",
    "                'name': name,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Visualizar resultados de performance\n",
    "    visualize_inference_performance(inference_results)\n",
    "    \n",
    "    return inference_results\n",
    "\n",
    "def visualize_inference_performance(results):\n",
    "    \"\"\"Visualiza performance de infer√™ncia\"\"\"\n",
    "    \n",
    "    successful_results = [r for r in results if r.get('success', False)]\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"‚ö†Ô∏è Nenhum resultado de infer√™ncia bem-sucedido\")\n",
    "        return\n",
    "    \n",
    "    names = [r['name'] for r in successful_results]\n",
    "    inference_times = [r['inference_time'] for r in successful_results]\n",
    "    fps_values = [r['fps'] for r in successful_results]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle('üéØ Performance de Infer√™ncia dos Modelos', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Tempo de infer√™ncia\n",
    "    bars1 = axes[0].bar(names, inference_times, color='lightblue', alpha=0.7)\n",
    "    axes[0].set_title('Tempo de Infer√™ncia')\n",
    "    axes[0].set_ylabel('Tempo (segundos)')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar, time_val in zip(bars1, inference_times):\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{time_val:.4f}s', ha='center', va='bottom')\n",
    "    \n",
    "    # FPS\n",
    "    bars2 = axes[1].bar(names, fps_values, color='lightgreen', alpha=0.7)\n",
    "    axes[1].set_title('Frames por Segundo (FPS)')\n",
    "    axes[1].set_ylabel('FPS')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar, fps_val in zip(bars2, fps_values):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{fps_val:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Executar teste de infer√™ncia\n",
    "inference_results = test_model_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üíæ SALVAR ARQUITETURAS DOS MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def save_model_architectures():\n",
    "    \"\"\"Salva arquiteturas dos modelos\"\"\"\n",
    "    \n",
    "    print(\"üíæ SALVANDO ARQUITETURAS DOS MODELOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    models_path = project_config['paths']['models']\n",
    "    os.makedirs(models_path, exist_ok=True)\n",
    "    \n",
    "    models_to_save = [\n",
    "        (\"unet_basic\", unet_basic),\n",
    "        (\"unet_attention\", unet_attention),\n",
    "        (\"unet_full\", unet_full),\n",
    "    ]\n",
    "    \n",
    "    # Adicionar outros modelos se dispon√≠veis\n",
    "    try:\n",
    "        models_to_save.extend([\n",
    "            (\"unet_resnet50\", unet_resnet),\n",
    "            (\"unet_efficientnet\", unet_efficientnet),\n",
    "        ])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        models_to_save.append((\"unet_plusplus\", unet_plusplus))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for name, model in models_to_save:\n",
    "        try:\n",
    "            # Salvar arquitetura em JSON\n",
    "            model_json = model.to_json()\n",
    "            json_path = os.path.join(models_path, f\"{name}_architecture.json\")\n",
    "            \n",
    "            with open(json_path, 'w') as f:\n",
    "                f.write(model_json)\n",
    "            \n",
    "            # Salvar summary em texto\n",
    "            summary_path = os.path.join(models_path, f\"{name}_summary.txt\")\n",
    "            \n",
    "            with open(summary_path, 'w') as f:\n",
    "                model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "            \n",
    "            print(f\"‚úÖ {name}: Arquitetura e sum√°rio salvos\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao salvar {name}: {e}\")\n",
    "    \n",
    "    # Salvar compara√ß√£o de modelos\n",
    "    try:\n",
    "        comparison_data = {\n",
    "            'models_comparison': models_info,\n",
    "            'inference_results': inference_results,\n",
    "            'created_at': str(pd.Timestamp.now()),\n",
    "            'tensorflow_version': tf.__version__\n",
    "        }\n",
    "        \n",
    "        comparison_path = os.path.join(models_path, 'models_comparison.json')\n",
    "        with open(comparison_path, 'w') as f:\n",
    "            json.dump(comparison_data, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"‚úÖ Compara√ß√£o de modelos salva em: {comparison_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao salvar compara√ß√£o: {e}\")\n",
    "\n",
    "# Salvar arquiteturas\n",
    "save_model_architectures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad611cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìã RECOMENDA√á√ïES DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_model_recommendations():\n",
    "    \"\"\"Gera recomenda√ß√µes de uso para cada modelo\"\"\"\n",
    "    \n",
    "    print(\"üìã RECOMENDA√á√ïES DE USO DOS MODELOS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    recommendations = {\n",
    "        \"U-Net B√°sica\": {\n",
    "            \"uso_recomendado\": \"Baseline e prototipagem r√°pida\",\n",
    "            \"vantagens\": [\n",
    "                \"Simples e f√°cil de treinar\",\n",
    "                \"Menor uso de mem√≥ria\",\n",
    "                \"Treinamento r√°pido\"\n",
    "            ],\n",
    "            \"desvantagens\": [\n",
    "                \"Performance limitada\",\n",
    "                \"Menos refinamento nas bordas\"\n",
    "            ],\n",
    "            \"cenarios\": [\n",
    "                \"Datasets pequenos\",\n",
    "                \"Prototipagem\",\n",
    "                \"Recursos computacionais limitados\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"U-Net + Aten√ß√£o\": {\n",
    "            \"uso_recomendado\": \"Segmenta√ß√£o de alta qualidade\",\n",
    "            \"vantagens\": [\n",
    "                \"Melhor detec√ß√£o de bordas\",\n",
    "                \"Foco em regi√µes relevantes\",\n",
    "                \"Boa performance geral\"\n",
    "            ],\n",
    "            \"desvantagens\": [\n",
    "                \"Ligeiramente mais complexa\",\n",
    "                \"Maior uso de mem√≥ria\"\n",
    "            ],\n",
    "            \"cenarios\": [\n",
    "                \"Aplica√ß√µes cl√≠nicas\",\n",
    "                \"Quando precis√£o √© cr√≠tica\",\n",
    "                \"Estruturas pequenas/complexas\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"U-Net + Aten√ß√£o + Residual\": {\n",
    "            \"uso_recomendado\": \"M√°xima performance\",\n",
    "            \"vantagens\": [\n",
    "                \"Melhor propaga√ß√£o de gradientes\",\n",
    "                \"Performance superior\",\n",
    "                \"Estabilidade de treinamento\"\n",
    "            ],\n",
    "            \"desvantagens\": [\n",
    "                \"Mais complexa\",\n",
    "                \"Maior tempo de treinamento\"\n",
    "            ],\n",
    "            \"cenarios\": [\n",
    "                \"Datasets grandes\",\n",
    "                \"M√°xima precis√£o necess√°ria\",\n",
    "                \"Recursos computacionais abundantes\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Adicionar recomenda√ß√µes para modelos com backbone\n",
    "    try:\n",
    "        recommendations[\"U-Net + ResNet50\"] = {\n",
    "            \"uso_recomendado\": \"Transfer learning e features robustas\",\n",
    "            \"vantagens\": [\n",
    "                \"Features pr√©-treinadas\",\n",
    "                \"Converg√™ncia mais r√°pida\",\n",
    "                \"Boa generaliza√ß√£o\"\n",
    "            ],\n",
    "            \"desvantagens\": [\n",
    "                \"Modelo grande\",\n",
    "                \"Requer mais mem√≥ria\"\n",
    "            ],\n",
    "            \"cenarios\": [\n",
    "                \"Datasets m√©dios/grandes\",\n",
    "                \"Transfer learning\",\n",
    "                \"Quando features naturais ajudam\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        recommendations[\"U-Net + EfficientNet-B0\"] = {\n",
    "            \"uso_recomendado\": \"Efici√™ncia computacional\",\n",
    "            \"vantagens\": [\n",
    "                \"Boa rela√ß√£o performance/efici√™ncia\",\n",
    "                \"Otimizado para mobile/edge\",\n",
    "                \"Features modernas\"\n",
    "            ],\n",
    "            \"desvantagens\": [\n",
    "                \"Menos investigado em medicina\",\n",
    "                \"Potencialmente menos est√°vel\"\n",
    "            ],\n",
    "            \"cenarios\": [\n",
    "                \"Deploy em produ√ß√£o\",\n",
    "                \"Recursos limitados\",\n",
    "                \"Aplica√ß√µes em tempo real\"\n",
    "            ]\n",
    "        }\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Adicionar recomenda√ß√£o para U-Net++\n",
    "    try:\n",
    "        recommendations[\"U-Net++\"] = {\n",
    "            \"uso_recomendado\": \"M√°xima precis√£o com supervis√£o profunda\",\n",
    "            \"vantagens\": [\n",
    "                \"M√∫ltiplos paths de informa√ß√£o\",\n",
    "                \"Supervis√£o em m√∫ltiplos n√≠veis\",\n",
    "                \"Performance state-of-the-art\"\n",
    "            ],\n",
    "            \"desvantagens\": [\n",
    "                \"Muito complexa\",\n",
    "                \"Treinamento lento\",\n",
    "                \"Alto uso de mem√≥ria\"\n",
    "            ],\n",
    "            \"cenarios\": [\n",
    "                \"Pesquisa acad√™mica\",\n",
    "                \"Quando precis√£o √© fundamental\",\n",
    "                \"Datasets muito grandes\"\n",
    "            ]\n",
    "        }\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Exibir recomenda√ß√µes\n",
    "    for model_name, rec in recommendations.items():\n",
    "        print(f\"\\nüèóÔ∏è {model_name}\")\n",
    "        print(f\"   üéØ Uso recomendado: {rec['uso_recomendado']}\")\n",
    "        \n",
    "        print(f\"   ‚úÖ Vantagens:\")\n",
    "        for advantage in rec['vantagens']:\n",
    "            print(f\"      ‚Ä¢ {advantage}\")\n",
    "        \n",
    "        print(f\"   ‚ö†Ô∏è Desvantagens:\")\n",
    "        for disadvantage in rec['desvantagens']:\n",
    "            print(f\"      ‚Ä¢ {disadvantage}\")\n",
    "        \n",
    "        print(f\"   üé™ Cen√°rios ideais:\")\n",
    "        for scenario in rec['cenarios']:\n",
    "            print(f\"      ‚Ä¢ {scenario}\")\n",
    "    \n",
    "    # Salvar recomenda√ß√µes\n",
    "    recommendations_path = os.path.join(project_config['paths']['outputs'], 'model_recommendations.json')\n",
    "    with open(recommendations_path, 'w') as f:\n",
    "        json.dump(recommendations, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Recomenda√ß√µes salvas em: {recommendations_path}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Gerar recomenda√ß√µes\n",
    "recommendations = generate_model_recommendations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50d16a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Resumo das Arquiteturas de Modelo\n",
    "\n",
    "### ‚úÖ Implementa√ß√µes Conclu√≠das\n",
    "\n",
    "1. **üèóÔ∏è U-Net Base Aprimorada**\n",
    "   - Blocos de convolu√ß√£o com BatchNorm e Dropout\n",
    "   - Conex√µes residuais opcionais\n",
    "   - Configura√ß√£o flex√≠vel de filtros\n",
    "\n",
    "2. **‚ö° Mecanismos de Aten√ß√£o**\n",
    "   - **Attention Gates**: Foco em regi√µes relevantes\n",
    "   - **Self-Attention**: Captura depend√™ncias espaciais\n",
    "   - **Channel Attention (SE)**: Aten√ß√£o por canal\n",
    "\n",
    "3. **üß† Backbones Pr√©-treinados**\n",
    "   - ResNet50 com weights do ImageNet\n",
    "   - EfficientNet-B0 otimizado\n",
    "   - DenseNet121 para features densas\n",
    "\n",
    "4. **üéØ Variantes Avan√ßadas**\n",
    "   - U-Net++ (Nested U-Net) com m√∫ltiplos paths\n",
    "   - Supervis√£o profunda (deep supervision)\n",
    "   - Configura√ß√µes otimizadas\n",
    "\n",
    "5. **üìä An√°lise Completa**\n",
    "   - Compara√ß√£o de complexidade\n",
    "   - Testes de infer√™ncia\n",
    "   - Recomenda√ß√µes de uso\n",
    "\n",
    "### üìà Principais Caracter√≠sticas\n",
    "\n",
    "- **üîß Modularidade**: Blocos reutiliz√°veis e configur√°veis\n",
    "- **‚ö° Performance**: Otimizado para GPU com mixed precision\n",
    "- **üéØ Flexibilidade**: M√∫ltiplas op√ß√µes arquiteturais\n",
    "- **üìä An√°lise**: Compara√ß√£o detalhada de modelos\n",
    "- **üíæ Persist√™ncia**: Arquiteturas salvas para reutiliza√ß√£o\n",
    "\n",
    "### üèÜ Modelos Recomendados por Cen√°rio\n",
    "\n",
    "| Cen√°rio | Modelo Recomendado | Justificativa |\n",
    "|---------|-------------------|---------------|\n",
    "| **Prototipagem** | U-Net B√°sica | Simplicidade e rapidez |\n",
    "| **Produ√ß√£o Cl√≠nica** | U-Net + Aten√ß√£o | Equil√≠brio performance/custo |\n",
    "| **M√°xima Precis√£o** | U-Net + Aten√ß√£o + Residual | Performance superior |\n",
    "| **Transfer Learning** | U-Net + ResNet50 | Features pr√©-treinadas |\n",
    "| **Deploy Eficiente** | U-Net + EfficientNet | Otimiza√ß√£o de recursos |\n",
    "| **Pesquisa Avan√ßada** | U-Net++ | Estado da arte |\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "\n",
    "1. **üìà Loss Functions**: Execute `04_Loss_Functions_and_Metrics.ipynb`\n",
    "2. **üöÄ Training Pipeline**: Execute `05_Training_Pipeline.ipynb`\n",
    "3. **üìã Model Evaluation**: Execute `06_Model_Evaluation.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "**‚ú® Arquiteturas implementadas e prontas para treinamento!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
