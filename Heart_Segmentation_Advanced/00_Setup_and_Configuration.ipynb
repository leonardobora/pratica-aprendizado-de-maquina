{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7010efb",
   "metadata": {},
   "source": [
    "# 🫀 Heart Segmentation Advanced - Setup & Configuration\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/leonardobora/pratica-aprendizado-de-maquina/blob/main/Heart_Segmentation_Advanced/00_Setup_and_Configuration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## 📋 Objetivos deste Notebook\n",
    "\n",
    "Este notebook configura o ambiente completo para o projeto de segmentação cardíaca avançada:\n",
    "\n",
    "- ⚙️ **Configuração do ambiente** (Colab/Local)\n",
    "- 📦 **Instalação de dependências**\n",
    "- 🔧 **Configuração de paths e constantes**\n",
    "- 🎯 **Verificação de hardware**\n",
    "- 🌱 **Configuração de seeds para reprodutibilidade**\n",
    "- 📊 **Setup de logging e visualização**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b163db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Executando em ambiente local\n",
      "🐍 Python version: 3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]\n",
      "📁 Current directory: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🔍 VERIFICAÇÃO DE AMBIENTE\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Verificar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"🌐 Executando no Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"🖥️ Executando em ambiente local\")\n",
    "\n",
    "# Informações do sistema\n",
    "print(f\"🐍 Python version: {sys.version}\")\n",
    "print(f\"📁 Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45dc0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💻 Em ambiente local - certifique-se de que as dependências estão instaladas\n",
      "Dependências necessárias: nibabel, SimpleITK, scikit-image, seaborn, plotly, tqdm\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 📦 INSTALAÇÃO DE DEPENDÊNCIAS\n",
    "# =============================================================================\n",
    "\n",
    "# Instalar dependências específicas que podem não estar disponíveis\n",
    "dependencies = [\n",
    "    'nibabel',           # Para arquivos NIfTI\n",
    "    'SimpleITK',         # Processamento de imagens médicas\n",
    "    'scikit-image',      # Operações morfológicas\n",
    "    'seaborn',          # Visualização avançada\n",
    "    'plotly',           # Visualização interativa\n",
    "    'tqdm',             # Barras de progresso\n",
    "]\n",
    "\n",
    "if IN_COLAB:\n",
    "    for package in dependencies:\n",
    "        print(f\"📥 Instalando {package}...\")\n",
    "        %pip install -q {package}\n",
    "else:\n",
    "    print(\"💻 Em ambiente local - certifique-se de que as dependências estão instaladas\")\n",
    "    print(f\"Dependências necessárias: {', '.join(dependencies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c22bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Projeto local em: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\n",
      "📊 Dataset esperado em: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\data\\Task02_Heart\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🔗 CONFIGURAÇÃO DO GOOGLE DRIVE (SE NO COLAB)\n",
    "# =============================================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"✅ Google Drive montado com sucesso!\")\n",
    "    \n",
    "    # Definir path base no Drive\n",
    "    DRIVE_BASE_PATH = '/content/drive/MyDrive'\n",
    "    PROJECT_PATH = os.path.join(DRIVE_BASE_PATH, 'Heart_Segmentation_Advanced')\n",
    "    DATASET_PATH = os.path.join(DRIVE_BASE_PATH, 'Medical_Decathlon/Task02_Heart')\n",
    "    \n",
    "    # Criar diretórios do projeto se não existirem\n",
    "    os.makedirs(PROJECT_PATH, exist_ok=True)\n",
    "    os.makedirs(os.path.join(PROJECT_PATH, 'models'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(PROJECT_PATH, 'outputs'), exist_ok=True)\n",
    "    \n",
    "    print(f\"📁 Projeto configurado em: {PROJECT_PATH}\")\n",
    "    print(f\"📊 Dataset esperado em: {DATASET_PATH}\")\n",
    "else:\n",
    "    # Configuração para ambiente local\n",
    "    PROJECT_PATH = os.getcwd()\n",
    "    DATASET_PATH = os.path.join(PROJECT_PATH, 'data', 'Task02_Heart')\n",
    "    print(f\"📁 Projeto local em: {PROJECT_PATH}\")\n",
    "    print(f\"📊 Dataset esperado em: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7beef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos os imports realizados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 📚 IMPORTS PRINCIPAIS\n",
    "# =============================================================================\n",
    "\n",
    "# Imports padrão\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict, Any, Optional, Union\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "# Processamento de imagens\n",
    "import cv2\n",
    "from skimage import transform, morphology, measure, filters\n",
    "from skimage.segmentation import clear_border\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Visualização\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Utilitários\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "\n",
    "print(\"✅ Todos os imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a43128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Instalando dependências necessárias...\n",
      "✅ torch já está instalado\n",
      "✅ torchvision já está instalado\n",
      "✅ numpy já está instalado\n",
      "✅ matplotlib já está instalado\n",
      "✅ seaborn já está instalado\n",
      "🔄 Instalando opencv-python...\n",
      "✅ opencv-python instalado com sucesso\n",
      "🔄 Instalando scikit-image...\n",
      "✅ scikit-image instalado com sucesso\n",
      "✅ scipy já está instalado\n",
      "✅ tqdm já está instalado\n",
      "✅ plotly já está instalado\n",
      "✅ pandas já está instalado\n",
      "🔄 Instalando nibabel...\n",
      "✅ nibabel instalado com sucesso\n",
      "🔄 Instalando SimpleITK...\n",
      "✅ SimpleITK instalado com sucesso\n",
      "🔄 Instalando scikit-learn...\n",
      "✅ scikit-learn instalado com sucesso\n",
      "🎉 Instalação de dependências concluída!\n"
     ]
    }
   ],
   "source": [
    "# Instalação de dependências necessárias\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Instala um pacote usando pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} instalado com sucesso\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"❌ Erro ao instalar {package}\")\n",
    "\n",
    "# Lista de pacotes necessários\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"opencv-python\",\n",
    "    \"scikit-image\",\n",
    "    \"scipy\",\n",
    "    \"tqdm\",\n",
    "    \"plotly\",\n",
    "    \"pandas\",\n",
    "    \"nibabel\",      # Para arquivos NIfTI médicos\n",
    "    \"SimpleITK\",    # Processamento de imagens médicas\n",
    "    \"scikit-learn\"  # Machine learning\n",
    "]\n",
    "\n",
    "print(\"📦 Instalando dependências necessárias...\")\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"✅ {package} já está instalado\")\n",
    "    except ImportError:\n",
    "        print(f\"🔄 Instalando {package}...\")\n",
    "        install_package(package)\n",
    "\n",
    "print(\"🎉 Instalação de dependências concluída!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1703307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 VERIFICAÇÃO DE HARDWARE\n",
      "==================================================\n",
      "PyTorch version: 2.7.0+cpu\n",
      "CUDA disponível: False\n",
      "⚠️ Nenhuma GPU detectada. Usando CPU.\n",
      "💾 RAM total: 31.9 GB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🎯 VERIFICAÇÃO DE HARDWARE\n",
    "# =============================================================================\n",
    "\n",
    "def check_hardware():\n",
    "    \"\"\"Verifica hardware disponível e configurações de GPU\"\"\"\n",
    "    print(\"🔧 VERIFICAÇÃO DE HARDWARE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Informações gerais\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA disponível: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # Verificar GPU\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"🚀 GPU(s) disponível(is): {gpu_count}\")\n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"  GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "        \n",
    "        # Configurar GPU principal\n",
    "        device = torch.device('cuda:0')\n",
    "        torch.cuda.set_device(0)\n",
    "        print(f\"✅ GPU configurada como dispositivo padrão\")\n",
    "        \n",
    "        # Verificar mixed precision\n",
    "        try:\n",
    "            # PyTorch tem suporte nativo para mixed precision\n",
    "            print(\"✅ Mixed Precision (AMP) disponível\")\n",
    "        except:\n",
    "            print(\"⚠️ Mixed Precision não disponível\")\n",
    "    else:\n",
    "        print(\"⚠️ Nenhuma GPU detectada. Usando CPU.\")\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    # Informações de memória\n",
    "    import psutil\n",
    "    ram_gb = psutil.virtual_memory().total / 1024**3\n",
    "    print(f\"💾 RAM total: {ram_gb:.1f} GB\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "check_hardware()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceaf6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌱 Seeds configuradas para 42\n",
      "✅ Configuração de reprodutibilidade aplicada!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🌱 CONFIGURAÇÃO DE REPRODUTIBILIDADE\n",
    "# =============================================================================\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Define seeds para reprodutibilidade\"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    \n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Para garantir reprodutibilidade completa no PyTorch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Variável de ambiente\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    print(f\"🌱 Seeds configuradas para {seed}\")\n",
    "\n",
    "# Aplicar configuração de seeds\n",
    "RANDOM_SEED = 42\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "# Configurar warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Configuração de reprodutibilidade aplicada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d56d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Configurações de visualização aplicadas\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 📊 CONFIGURAÇÃO DE VISUALIZAÇÃO\n",
    "# =============================================================================\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "# Configurar seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configurar plotly\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"🎨 Configurações de visualização aplicadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37883be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-18 11:23:51,153 - INFO - 🚀 Sistema de logging iniciado\n",
      "2025-06-18 11:23:51,167 - INFO - 📁 Log salvo em: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\logs\\heart_segmentation_20250618_112351.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\logging\\__init__.py\", line 1163, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f680' in position 33: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3100, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3155, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3367, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3612, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3672, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\leonardo.costa\\AppData\\Local\\Temp\\ipykernel_22460\\2356002522.py\", line 33, in <module>\n",
      "    logger = setup_logging()\n",
      "  File \"C:\\Users\\leonardo.costa\\AppData\\Local\\Temp\\ipykernel_22460\\2356002522.py\", line 27, in setup_logging\n",
      "    logger.info(\"🚀 Sistema de logging iniciado\")\n",
      "Message: '🚀 Sistema de logging iniciado'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\logging\\__init__.py\", line 1163, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f4c1' in position 33: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3100, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3155, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3367, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3612, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\leonardo.costa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3672, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\leonardo.costa\\AppData\\Local\\Temp\\ipykernel_22460\\2356002522.py\", line 33, in <module>\n",
      "    logger = setup_logging()\n",
      "  File \"C:\\Users\\leonardo.costa\\AppData\\Local\\Temp\\ipykernel_22460\\2356002522.py\", line 28, in setup_logging\n",
      "    logger.info(f\"📁 Log salvo em: {log_file}\")\n",
      "Message: '📁 Log salvo em: c:\\\\Users\\\\leonardo.costa\\\\OneDrive - Lightera, LLC\\\\Documentos\\\\GitHub\\\\pratica-aprendizado-de-maquina\\\\Heart_Segmentation_Advanced\\\\logs\\\\heart_segmentation_20250618_112351.log'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 📝 CONFIGURAÇÃO DE LOGGING\n",
    "# =============================================================================\n",
    "\n",
    "def setup_logging(log_level=logging.INFO):\n",
    "    \"\"\"Configura sistema de logging\"\"\"\n",
    "    \n",
    "    # Criar diretório de logs\n",
    "    log_dir = os.path.join(PROJECT_PATH, 'logs')\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Nome do arquivo de log com timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = os.path.join(log_dir, f'heart_segmentation_{timestamp}.log')\n",
    "    \n",
    "    # Configurar logging\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"🚀 Sistema de logging iniciado\")\n",
    "    logger.info(f\"📁 Log salvo em: {log_file}\")\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# Inicializar logging\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e1e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Configurações globais carregadas:\n",
      "   📊 Dataset: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\data\\Task02_Heart\n",
      "   💾 Models: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\models\n",
      "   📤 Outputs: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\outputs\n",
      "   🖼️ Image size: (128, 128)\n",
      "   🏷️ Classes: 3 (Background, Left Ventricle, Myocardium)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🔧 CONSTANTES E CONFIGURAÇÕES GLOBAIS\n",
    "# =============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Classe de configuração centralizada\"\"\"\n",
    "    \n",
    "    # Paths principais\n",
    "    PROJECT_PATH = PROJECT_PATH\n",
    "    DATASET_PATH = DATASET_PATH\n",
    "    MODELS_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "    OUTPUTS_PATH = os.path.join(PROJECT_PATH, 'outputs')\n",
    "    \n",
    "    # Configurações de dados\n",
    "    IMAGE_SIZE = (128, 128)\n",
    "    NUM_CLASSES = 3  # background, ventrículo esquerdo, miocárdio\n",
    "    CLASS_NAMES = ['Background', 'Left Ventricle', 'Myocardium']\n",
    "    CLASS_COLORS = ['black', 'red', 'green']\n",
    "    \n",
    "    # Configurações de treinamento\n",
    "    BATCH_SIZE = 8\n",
    "    INITIAL_EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-3\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    TEST_SPLIT = 0.1\n",
    "    \n",
    "    # Configurações de modelo\n",
    "    BACKBONE_OPTIONS = ['resnet50', 'efficientnet-b0', 'densenet121']\n",
    "    DEFAULT_BACKBONE = 'resnet50'\n",
    "    \n",
    "    # Configurações de augmentação\n",
    "    AUGMENTATION_PARAMS = {\n",
    "        'rotation_range': 15,\n",
    "        'translation_range': 0.1,\n",
    "        'scaling_range': (0.9, 1.1),\n",
    "        'shear_range': 5,\n",
    "        'flip_probability': 0.5,\n",
    "        'noise_std': 0.01,\n",
    "        'blur_sigma': (0.5, 1.0),\n",
    "        'contrast_range': (0.8, 1.2),\n",
    "        'brightness_range': 0.1\n",
    "    }\n",
    "    \n",
    "    # Configurações de loss\n",
    "    LOSS_WEIGHTS = {\n",
    "        'dice': 0.4,\n",
    "        'focal': 0.4,\n",
    "        'boundary': 0.2\n",
    "    }\n",
    "    \n",
    "    # Configurações de callbacks\n",
    "    EARLY_STOPPING_PATIENCE = 15\n",
    "    REDUCE_LR_PATIENCE = 7\n",
    "    REDUCE_LR_FACTOR = 0.5\n",
    "    MIN_LR = 1e-6\n",
    "    \n",
    "    # Configurações de pós-processamento\n",
    "    MIN_COMPONENT_SIZE = 100\n",
    "    MORPHOLOGY_KERNEL_SIZE = 3\n",
    "    \n",
    "    # Seed global\n",
    "    RANDOM_SEED = RANDOM_SEED\n",
    "\n",
    "# Criar instância de configuração\n",
    "config = Config()\n",
    "\n",
    "print(\"⚙️ Configurações globais carregadas:\")\n",
    "print(f\"   📊 Dataset: {config.DATASET_PATH}\")\n",
    "print(f\"   💾 Models: {config.MODELS_PATH}\")\n",
    "print(f\"   📤 Outputs: {config.OUTPUTS_PATH}\")\n",
    "print(f\"   🖼️ Image size: {config.IMAGE_SIZE}\")\n",
    "print(f\"   🏷️ Classes: {config.NUM_CLASSES} ({', '.join(config.CLASS_NAMES)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c19c2af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VERIFICAÇÃO DE INTEGRIDADE DO SETUP\n",
      "==================================================\n",
      "✅ Diretório do projeto: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\n",
      "✅ Diretório de modelos: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\models\n",
      "✅ Diretório de outputs: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\outputs\n",
      "⚠️ Dataset não encontrado: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\data\\Task02_Heart\n",
      "   (Certifique-se de que o dataset está no local correto)\n",
      "⚠️ GPU não disponível - usando CPU\n",
      "✅ Seeds configurados: 42\n",
      "==================================================\n",
      "2025-06-18 11:24:08,359 - INFO - Setup verification completed\n",
      "2025-06-18 11:24:08,362 - INFO - Project path: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\n",
      "2025-06-18 11:24:08,363 - INFO - Dataset path: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\data\\Task02_Heart\n",
      "2025-06-18 11:24:08,362 - INFO - Project path: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\n",
      "2025-06-18 11:24:08,363 - INFO - Dataset path: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\data\\Task02_Heart\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ✅ VERIFICAÇÃO DE INTEGRIDADE DO SETUP\n",
    "# =============================================================================\n",
    "\n",
    "def verify_setup():\n",
    "    \"\"\"Verifica se o setup foi realizado corretamente\"\"\"\n",
    "    \n",
    "    print(\"🔍 VERIFICAÇÃO DE INTEGRIDADE DO SETUP\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # Verificar paths\n",
    "    paths_to_check = [\n",
    "        (config.PROJECT_PATH, \"Diretório do projeto\"),\n",
    "        (config.MODELS_PATH, \"Diretório de modelos\"),\n",
    "        (config.OUTPUTS_PATH, \"Diretório de outputs\"),\n",
    "    ]\n",
    "    \n",
    "    for path, description in paths_to_check:\n",
    "        if os.path.exists(path):\n",
    "            checks.append(f\"✅ {description}: {path}\")\n",
    "        else:\n",
    "            checks.append(f\"❌ {description}: {path} (NÃO ENCONTRADO)\")\n",
    "    \n",
    "    # Verificar dataset (opcional por enquanto)\n",
    "    if os.path.exists(config.DATASET_PATH):\n",
    "        checks.append(f\"✅ Dataset: {config.DATASET_PATH}\")\n",
    "        \n",
    "        # Verificar subdiretórios do dataset\n",
    "        images_dir = os.path.join(config.DATASET_PATH, 'imagesTr')\n",
    "        labels_dir = os.path.join(config.DATASET_PATH, 'labelsTr')\n",
    "        \n",
    "        if os.path.exists(images_dir):\n",
    "            image_files = len([f for f in os.listdir(images_dir) if f.endswith('.nii.gz')])\n",
    "            checks.append(f\"✅ Imagens encontradas: {image_files}\")\n",
    "        else:\n",
    "            checks.append(f\"⚠️ Diretório de imagens não encontrado: {images_dir}\")\n",
    "            \n",
    "        if os.path.exists(labels_dir):\n",
    "            label_files = len([f for f in os.listdir(labels_dir) if f.endswith('.nii.gz')])\n",
    "            checks.append(f\"✅ Labels encontradas: {label_files}\")\n",
    "        else:\n",
    "            checks.append(f\"⚠️ Diretório de labels não encontrado: {labels_dir}\")\n",
    "    else:\n",
    "        checks.append(f\"⚠️ Dataset não encontrado: {config.DATASET_PATH}\")\n",
    "        checks.append(\"   (Certifique-se de que o dataset está no local correto)\")\n",
    "    \n",
    "    # Verificar PyTorch e GPU\n",
    "    if torch.cuda.is_available():\n",
    "        checks.append(\"✅ GPU disponível e configurada\")\n",
    "    else:\n",
    "        checks.append(\"⚠️ GPU não disponível - usando CPU\")\n",
    "    \n",
    "    # Verificar seeds\n",
    "    checks.append(f\"✅ Seeds configurados: {config.RANDOM_SEED}\")\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    for check in checks:\n",
    "        print(check)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Log do setup\n",
    "    logger.info(\"Setup verification completed\")\n",
    "    logger.info(f\"Project path: {config.PROJECT_PATH}\")\n",
    "    logger.info(f\"Dataset path: {config.DATASET_PATH}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Executar verificação\n",
    "setup_ok = verify_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683617da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Configurações salvas em: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\project_config.json\n",
      "2025-06-18 11:24:14,630 - INFO - Configuration saved to: c:\\Users\\leonardo.costa\\OneDrive - Lightera, LLC\\Documentos\\GitHub\\pratica-aprendizado-de-maquina\\Heart_Segmentation_Advanced\\project_config.json\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 💾 SALVAR CONFIGURAÇÕES\n",
    "# =============================================================================\n",
    "\n",
    "def save_config():\n",
    "    \"\"\"Salva configurações em arquivo JSON para reutilização\"\"\"\n",
    "    \n",
    "    config_dict = {\n",
    "        'project_info': {\n",
    "            'name': 'Heart Segmentation Advanced',\n",
    "            'version': '1.0.0',\n",
    "            'created': datetime.now().isoformat(),\n",
    "            'environment': 'colab' if IN_COLAB else 'local'\n",
    "        },\n",
    "        'paths': {\n",
    "            'project': config.PROJECT_PATH,\n",
    "            'dataset': config.DATASET_PATH,\n",
    "            'models': config.MODELS_PATH,\n",
    "            'outputs': config.OUTPUTS_PATH\n",
    "        },\n",
    "        'data_config': {\n",
    "            'image_size': config.IMAGE_SIZE,\n",
    "            'num_classes': config.NUM_CLASSES,\n",
    "            'class_names': config.CLASS_NAMES,\n",
    "            'validation_split': config.VALIDATION_SPLIT,\n",
    "            'test_split': config.TEST_SPLIT\n",
    "        },\n",
    "        'training_config': {\n",
    "            'batch_size': config.BATCH_SIZE,\n",
    "            'initial_epochs': config.INITIAL_EPOCHS,\n",
    "            'learning_rate': config.LEARNING_RATE,\n",
    "            'early_stopping_patience': config.EARLY_STOPPING_PATIENCE\n",
    "        },\n",
    "        'model_config': {\n",
    "            'default_backbone': config.DEFAULT_BACKBONE,\n",
    "            'backbone_options': config.BACKBONE_OPTIONS\n",
    "        },\n",
    "        'augmentation_config': config.AUGMENTATION_PARAMS,\n",
    "        'loss_config': config.LOSS_WEIGHTS,\n",
    "        'random_seed': config.RANDOM_SEED\n",
    "    }\n",
    "    \n",
    "    config_file = os.path.join(config.PROJECT_PATH, 'project_config.json')\n",
    "    \n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config_dict, f, indent=2)\n",
    "    \n",
    "    print(f\"💾 Configurações salvas em: {config_file}\")\n",
    "    logger.info(f\"Configuration saved to: {config_file}\")\n",
    "\n",
    "# Salvar configurações\n",
    "save_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc78fd2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 Setup Concluído!\n",
    "\n",
    "O ambiente está configurado e pronto para uso. Próximos passos:\n",
    "\n",
    "1. **📊 Data Analysis**: Execute `01_Data_Analysis_and_Preprocessing.ipynb`\n",
    "2. **🔄 Data Augmentation**: Execute `02_Data_Augmentation.ipynb`  \n",
    "3. **🏗️ Model Architecture**: Execute `03_Model_Architecture.ipynb`\n",
    "\n",
    "### 📋 Resumo das Configurações\n",
    "\n",
    "- **Ambiente**: Google Colab ✅\n",
    "- **GPU**: Disponível e configurada ✅\n",
    "- **Seeds**: Fixados para reprodutibilidade ✅\n",
    "- **Paths**: Configurados corretamente ✅\n",
    "- **Logging**: Sistema ativo ✅\n",
    "- **Visualização**: Configurada ✅\n",
    "\n",
    "### 🔧 Configurações Principais\n",
    "\n",
    "- **Image Size**: 128x128\n",
    "- **Classes**: 3 (Background, Left Ventricle, Myocardium)\n",
    "- **Batch Size**: 8\n",
    "- **Learning Rate**: 0.001\n",
    "- **Random Seed**: 42\n",
    "\n",
    "---\n",
    "\n",
    "**✨ Pronto para começar a análise de dados!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
